<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Mic Delay with CAT Audio</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
  </style>
</head>
<body>
  <h1>Mic Delay with CAT Logic</h1>
  <p>Status: <span id="status">Starting...</span></p>

  <script>
    const status = document.getElementById('status');
    let audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    let micStream, micSource, micGain, delayNode;
    let catPlayer = new Audio();
    catPlayer.volume = 1.0;

    async function setupMic() {
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      micSource = audioCtx.createMediaStreamSource(micStream);

      // Gain for boosting weak input
      micGain = audioCtx.createGain();
      micGain.gain.value = 2.0;

      // Delay playback by 3 seconds
      delayNode = audioCtx.createDelay(5.0);
      delayNode.delayTime.value = 3.0;

      // Output to speakers
      micSource.connect(micGain);
      micGain.connect(delayNode);
      delayNode.connect(audioCtx.destination);

      monitorMicVolume(micStream);

      startSpeechLoop();
      status.textContent = "Running";
    }

    function monitorMicVolume(stream) {
      const analyser = audioCtx.createAnalyser();
      const buffer = new Uint8Array(analyser.fftSize);
      const micMonitor = audioCtx.createMediaStreamSource(stream);
      micMonitor.connect(analyser);

      function adjustVolume() {
        analyser.getByteTimeDomainData(buffer);
        let sum = 0;
        for (let i = 0; i < buffer.length; i++) {
          let val = (buffer[i] - 128) / 128;
          sum += val * val;
        }
        let rms = Math.sqrt(sum / buffer.length);
        // Boost volume if quiet
        micGain.gain.value = rms < 0.01 ? 4.0 : 1.0;
        requestAnimationFrame(adjustVolume);
      }

      adjustVolume();
    }

    function startSpeechLoop() {
      setInterval(runSpeechAnalysis, 10000);
    }

    async function runSpeechAnalysis() {
      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = 'en-US';
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.start();
      status.textContent = "Listening...";

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript.trim();
        const wordCount = transcript.split(/\s+/).length;
        status.textContent = `Heard: "${transcript}" (${wordCount} words)`;
        playCatByWordCount(wordCount);
      };

      recognition.onerror = () => {
        status.textContent = "No speech detected";
        playCatByWordCount(0);
      };
    }

    function playCatByWordCount(count) {
      let file = 'CAT1.mp3';
      if (count >= 1 && count <= 3) file = 'CAT2.mp3';
      else if (count > 3) file = 'CAT3.mp3';

      catPlayer.src = file;
      catPlayer.play();
    }

    setupMic();
  </script>
</body>
</html>





