<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="UTF-8" />
<title>CAT Loop Audio avec Micro</title>
<style>
  body {
    background: black;
    color: white;
    font-family: sans-serif;
    text-align: center;
    padding: 20px;
  }
  button {
    font-size: 18px;
    padding: 10px 20px;
    margin-top: 20px;
    cursor: pointer;
  }
</style>
</head>
<body>
  <h1>CAT Loop Audio avec Micro</h1>
  <p>Status: <span id="status">En attente...</span></p>
  <button id="startBtn">Démarrer</button>

<script>
const status = document.getElementById('status');
const startBtn = document.getElementById('startBtn');

let audioCtx;
let micStream, micSource, micGain, delayNode;
let catPlayer = new Audio();
catPlayer.loop = true;
let currentCat = "CAT1.mp3";
let currentRMS = 0.05;
let recognition;

startBtn.onclick = async () => {
  startBtn.style.display = "none";
  status.textContent = "Initialisation...";
  await setupAudio();
  playCAT(currentCat);
  setupSpeechLoop();
  status.textContent = "En cours...";
};

async function setupAudio() {
  audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  micSource = audioCtx.createMediaStreamSource(micStream);

  micGain = audioCtx.createGain();
  micGain.gain.value = 2.0;

  delayNode = audioCtx.createDelay(5.0);
  delayNode.delayTime.value = 3.0;

  micSource.connect(micGain);
  micGain.connect(delayNode);
  delayNode.connect(audioCtx.destination);

  monitorMicVolume(micStream);

  catPlayer.volume = 1.0;
}

function monitorMicVolume(stream) {
  const analyser = audioCtx.createAnalyser();
  const buffer = new Uint8Array(analyser.fftSize);
  const micMonitor = audioCtx.createMediaStreamSource(stream);
  micMonitor.connect(analyser);

  function update() {
    analyser.getByteTimeDomainData(buffer);
    let sum = 0;
    for (let i = 0; i < buffer.length; i++) {
      let val = (buffer[i] - 128) / 128;
      sum += val * val;
    }
    currentRMS = Math.sqrt(sum / buffer.length);
    micGain.gain.value = currentRMS < 0.01 ? 4.0 : 1.0;
    // Modulate CAT audio pitch and volume live:
    if (!catPlayer.paused) {
      const mod = Math.min(currentRMS * 10, 2.0);
      catPlayer.playbackRate = 0.8 + mod * 0.4;
      catPlayer.volume = Math.min(0.3 + mod * 0.7, 1.0);
    }
    requestAnimationFrame(update);
  }
  update();
}

function setupSpeechLoop() {
  setInterval(() => runSpeechAnalysis(), 10000);
}

function runSpeechAnalysis() {
  if (recognition) {
    recognition.abort();
    recognition = null;
  }

  recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = 'fr-FR';
  recognition.interimResults = false;
  recognition.maxAlternatives = 1;

  recognition.onstart = () => {
    status.textContent = "Écoute...";
  };

  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript.trim();
    const wordCount = transcript.split(/\s+/).filter(w => w.length > 0).length;
    status.textContent = `Entendu : "${transcript}" (${wordCount} mots)`;
    selectCAT(wordCount);
  };

  recognition.onerror = () => {
    status.textContent = "Aucun mot détecté.";
    selectCAT(0);
  };

  recognition.start();
}

function selectCAT(wordCount) {
  let catFile = "CAT1.mp3";
  if (wordCount >= 1 && wordCount <= 3) catFile = "CAT2.mp3";
  else if (wordCount > 3) catFile = "CAT3.mp3";

  if (catFile !== currentCat) {
    currentCat = catFile;
    playCAT(currentCat);
  }
}

function playCAT(file) {
  catPlayer.pause();
  catPlayer.src = file;
  catPlayer.load();
  catPlayer.play().catch(e => {
    status.textContent = "Lecture audio bloquée.";
    console.error(e);
  });
}
</script>
</body>
</html>




