<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Inverse Voice Reaction + Modulated Speaking Sound</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
    button {
      font-size: 18px;
      margin: 10px;
      padding: 10px 20px;
      cursor: pointer;
    }
  </style>
</head>
<body>

<h1>üé§ Inverse Voice Reaction + Modulated Speaking Sound 1.0</h1>
<button onclick="startProcess()">üéß D√©marrer</button>
<div id="status">Pr√™t.</div>

<script>
  const keywordMap = {
    "ok": ["M/a2.mp3", "M/ok2.mp3", "M/ok3.mp3"],
    "oui": ["M/a3.mp3", "M/oui2.mp3", "M/oui3.mp3"]
  };
  const fallbackClips = ["M/merci1.mp3", "M/merci2.mp3", "M/merci3.mp3"];
  const recordStartSound = "start-sound.mp3";       // sound when recording starts
  const speakingSound = "speaking-sound.mp3";       // looping speaking sound during recording
  const RECORD_DURATION = 3000;

  let mediaRecorder, audioCtx, analyser;
  let recordedChunks = [], recordedBlob, responsePath;
  let userPitch = 200, userVolume = 0.1, userSpeed = 0.05;

  let speakingSource = null;
  let speakingGain = null;
  let speakingBuffer = null;
  let isRecording = false;

  function startProcess() {
    recordedChunks = [];
    responsePath = null;

    audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();

    playStartSound().then(() => {
      navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
        mediaRecorder = new MediaRecorder(stream);
        const micSource = audioCtx.createMediaStreamSource(stream);
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        micSource.connect(analyser);

        mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);

        mediaRecorder.onstart = () => {
          playSpeakingSound();
        };

        mediaRecorder.onstop = () => {
          stopSpeakingSound();
          recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
          analyzeMicInput();
          transcribeRecording();
        };

        mediaRecorder.start();
        document.getElementById("status").textContent = "üéôÔ∏è Enregistrement...";
        setTimeout(() => mediaRecorder.stop(), RECORD_DURATION);
      });
    });
  }

  function playStartSound() {
    return new Promise(resolve => {
      const sound = new Audio(recordStartSound);
      sound.volume = 0.5;
      sound.onended = resolve;
      sound.play();
    });
  }

  function playSpeakingSound() {
    if (speakingSource) return; // already playing
    fetch(speakingSound)
      .then(res => res.arrayBuffer())
      .then(data => audioCtx.decodeAudioData(data))
      .then(buffer => {
        speakingBuffer = buffer;
        speakingSource = audioCtx.createBufferSource();
        speakingGain = audioCtx.createGain();

        speakingSource.buffer = speakingBuffer;
        speakingSource.loop = true;

        speakingSource.connect(speakingGain).connect(audioCtx.destination);
        speakingGain.gain.value = 0.3;

        speakingSource.start();

        isRecording = true;
        updateSpeakingSoundParams();
      });
  }

  function stopSpeakingSound() {
    isRecording = false;
    if (!speakingSource) return;
    speakingSource.stop();
    speakingSource.disconnect();
    speakingGain.disconnect();
    speakingSource = null;
    speakingGain = null;
  }

  function updateSpeakingSoundParams() {
    if (!isRecording || !speakingSource || !speakingGain) return;

    const bufferLength = analyser.fftSize;
    const data = new Float32Array(bufferLength);
    analyser.getFloatTimeDomainData(data);

    // Pitch estimation (autocorrelation)
    let maxCorr = 0, bestLag = 0;
    for (let lag = 16; lag < 1000; lag++) {
      let corr = 0;
      for (let i = 0; i < bufferLength - lag; i++) {
        corr += data[i] * data[i + lag];
      }
      if (corr > maxCorr) {
        maxCorr = corr;
        bestLag = lag;
      }
    }
    const pitch = bestLag > 0 ? (audioCtx.sampleRate / bestLag) : 200;

    // Volume estimation (RMS)
    let sumSquares = 0;
    for (let i = 0; i < bufferLength; i++) {
      sumSquares += data[i] * data[i];
    }
    const volume = Math.min(Math.sqrt(sumSquares / bufferLength), 1);

    // Map pitch and volume to speaking sound playbackRate and gain
    let playbackRate = 1 + (pitch - 200) / 600;
    playbackRate = Math.min(Math.max(playbackRate, 0.8), 1.2);
    speakingSource.playbackRate.value = playbackRate;

    speakingGain.gain.value = 0.1 + volume * 0.5;

    requestAnimationFrame(updateSpeakingSoundParams);
  }

  function analyzeMicInput() {
    const bufferLength = analyser.fftSize;
    const data = new Float32Array(bufferLength);
    analyser.getFloatTimeDomainData(data);

    // Pitch estimation via autocorrelation
    let maxCorr = 0, bestLag = 0;
    for (let lag = 16; lag < 1000; lag++) {
      let corr = 0;
      for (let i = 0; i < bufferLength - lag; i++) {
        corr += data[i] * data[i + lag];
      }
      if (corr > maxCorr) {
        maxCorr = corr;
        bestLag = lag;
      }
    }
    userPitch = bestLag > 0 ? (audioCtx.sampleRate / bestLag) : 200;

    // Volume estimation (RMS)
    let sumSquares = 0;
    for (let i = 0; i < bufferLength; i++) {
      sumSquares += data[i] * data[i];
    }
    userVolume = Math.min(Math.sqrt(sumSquares / bufferLength), 1);

    // Speed estimation (zero-crossings)
    let crossings = 0;
    for (let i = 1; i < bufferLength; i++) {
      if ((data[i - 1] < 0 && data[i] >= 0) || (data[i - 1] > 0 && data[i] <= 0)) {
        crossings++;
      }
    }
    userSpeed = crossings / bufferLength;
  }

  function transcribeRecording() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      responsePath = randomFromArray(fallbackClips);
      playInvertedMP3(responsePath);
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "fr-FR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onresult = e => {
      const txt = e.results[0][0].transcript.toLowerCase();
      document.getElementById("status").textContent = `‚úÖ Vous avez dit : "${txt}"`;
      for (const key in keywordMap) {
        if (txt.includes(key)) {
          responsePath = randomFromArray(keywordMap[key]);
          playInvertedMP3(responsePath);
          return;
        }
      }
      responsePath = randomFromArray(fallbackClips);
      playInvertedMP3(responsePath);
    };

    recognition.onerror = e => {
      document.getElementById("status").textContent = "‚ùå Erreur : " + e.error;
      responsePath = randomFromArray(fallbackClips);
      playInvertedMP3(responsePath);
    };

    recognition.start();
    setTimeout(() => recognition.stop(), 3000);
  }

  function playInvertedMP3(path) {
    fetch(path)
      .then(res => res.arrayBuffer())
      .then(data => audioCtx.decodeAudioData(data))
      .then(buffer => {
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;

        // Adjusted inversion logic ‚Äî believable range
        const pitchFactor = 1.3 - (userPitch / 400); 
        const speedFactor = 1.1 - userSpeed;        
        const volumeFactor = 1.4 - userVolume * 1.2; 

        const finalRate = Math.min(Math.max(speedFactor * pitchFactor, 0.75), 1.3);
        source.playbackRate.value = finalRate;

        const gainNode = audioCtx.createGain();
        gainNode.gain.value = Math.min(Math.max(volumeFactor, 0.5), 1.5);

        const filter = audioCtx.createBiquadFilter();
        filter.type = "lowshelf";
        filter.frequency.value = 1000;
        filter.gain.value = pitchFactor > 1 ? -5 : 5;

        source.connect(filter).connect(gainNode).connect(audioCtx.destination);
        source.onended = () => startProcess();
        source.start(0);

        document.getElementById("status").textContent =
          `üîÑ R√©action invers√©e ‚Äî rate: ${finalRate.toFixed(2)}, gain: ${gainNode.gain.value.toFixed(2)}`;
      })
      .catch(err => {
        document.getElementById("status").textContent = "‚ö†Ô∏è Erreur lecture MP3 : " + err;
        startProcess();
      });
  }

  function randomFromArray(arr) {
    return arr[Math.floor(Math.random() * arr.length)];
  }
</script>

</body>
</html>

