<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Soft Opposition Voice Reaction</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
    button {
      font-size: 18px;
      margin: 10px;
      padding: 10px 20px;
      cursor: pointer;
    }
    #log {
      max-height: 200px;
      overflow-y: auto;
      border: 1px solid gray;
      margin-top: 20px;
      padding: 10px;
      background: #111;
      text-align: left;
      font-size: 14px;
    }
  </style>
</head>
<body>

<h1>üé§ Soft Opposition Voice Reaction2</h1>
<button id="startBtn">üéß D√©marrer</button>
<div id="status">Pr√™t.</div>
<div id="log"></div>

<script>
  const keywordMap = {
    "ok": ["M/a2.mp3"],
    "oui": ["M/a3.mp3"]
  };
  const fallbackClips = ["M/merci1.mp3", "M/merci2.mp3", "M/merci3.mp3"];
  let unusedFallbacks = [...fallbackClips];

  const recordStartSound = "click.mp3";
  const RECORD_DURATION = 3000;

  let audioCtx = null;
  let mediaRecorder = null;
  let recordedChunks = [];
  let userPitch = 200, userSpeed = 0.05, userVolume = 0.1;

  document.getElementById("startBtn").onclick = () => {
    startProcess();
  };

  async function startProcess() {
    try {
      if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      if (audioCtx.state === 'suspended') await audioCtx.resume();

      recordedChunks = [];
      updateStatus("üîä Jouer son de d√©marrage...");
      await playStartSound();

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      startRecognition();

      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'audio/webm' });
        analyzeAndPlay(blob);
      };

      mediaRecorder.start();
      updateStatus("üéôÔ∏è Enregistrement...");
      setTimeout(() => mediaRecorder.stop(), RECORD_DURATION);
    } catch (err) {
      console.error(err);
      updateStatus("‚ùå Erreur : " + err.message);
    }
  }

  function updateStatus(text) {
    document.getElementById("status").textContent = text;
  }

  function playStartSound() {
    return new Promise((resolve) => {
      const sound = new Audio(recordStartSound);
      sound.volume = 0.5;
      sound.onended = resolve;
      sound.onerror = () => resolve();
      sound.play().catch(() => resolve());
    });
  }

  function analyzeAndPlay(blob) {
    const reader = new FileReader();
    reader.onload = e => {
      audioCtx.decodeAudioData(e.target.result).then(buffer => {
        analyzeRecordedAudio(buffer);
        chooseAndPlayMP3();
      }).catch(err => {
        console.error("Audio decode error:", err);
        updateStatus("‚ö†Ô∏è Erreur d√©codage audio");
        setTimeout(startProcess, 1000);
      });
    };
    reader.readAsArrayBuffer(blob);
  }

  function analyzeRecordedAudio(buffer) {
    const rawData = buffer.getChannelData(0);
    const sampleRate = buffer.sampleRate;

    let maxCorr = 0, bestLag = 0;
    for (let lag = 16; lag < 1000; lag++) {
      let corr = 0;
      for (let i = 0; i < rawData.length - lag; i++) {
        corr += rawData[i] * rawData[i + lag];
      }
      if (corr > maxCorr) {
        maxCorr = corr;
        bestLag = lag;
      }
    }
    userPitch = bestLag > 0 ? (sampleRate / bestLag) : 200;

    let sumSquares = 0;
    for (let i = 0; i < rawData.length; i++) {
      sumSquares += rawData[i] * rawData[i];
    }
    userVolume = Math.min(Math.sqrt(sumSquares / rawData.length), 1);

    let crossings = 0;
    for (let i = 1; i < rawData.length; i++) {
      if ((rawData[i - 1] < 0 && rawData[i] >= 0) || (rawData[i - 1] > 0 && rawData[i] <= 0)) {
        crossings++;
      }
    }
    userSpeed = crossings / rawData.length;

    console.log(`Analyse: pitch=${userPitch.toFixed(1)}, volume=${userVolume.toFixed(2)}, speed=${userSpeed.toFixed(3)}`);
  }

  let lastRecognizedText = "";

  function startRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) return;

    const recognition = new SpeechRecognition();
    recognition.lang = "fr-FR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onresult = e => {
      lastRecognizedText = e.results[0][0].transcript.toLowerCase();
      updateStatus(`‚úÖ Vous avez dit : "${lastRecognizedText}"`);
    };

    recognition.onerror = e => {
      console.warn("Erreur reconnaissance:", e.error);
      lastRecognizedText = "";
    };

    recognition.start();
    setTimeout(() => { try { recognition.stop(); } catch {} }, RECORD_DURATION);
  }

  function chooseAndPlayMP3() {
    let foundKey = null;
    for (const key in keywordMap) {
      if (lastRecognizedText.includes(key)) {
        foundKey = key;
        break;
      }
    }

    let chosenPath;
    if (foundKey) {
      chosenPath = randomFromArray(keywordMap[foundKey]);
    } else {
      if (unusedFallbacks.length === 0) unusedFallbacks = [...fallbackClips];
      const index = Math.floor(Math.random() * unusedFallbacks.length);
      chosenPath = unusedFallbacks.splice(index, 1)[0];
    }

    logTranscript(lastRecognizedText || "(rien)", chosenPath);
    playSoftOppositionMP3(chosenPath);
  }

  function playSoftOppositionMP3(path) {
    fetch(path)
      .then(res => res.arrayBuffer())
      .then(data => audioCtx.decodeAudioData(data))
      .then(buffer => {
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;

        const pitchFactor = 1.25 - (userPitch / 700);
        const speedFactor = 1.1 - userSpeed * 0.8;
        const finalRate = Math.min(Math.max(pitchFactor * speedFactor, 0.7), 1.3);
        source.playbackRate.value = finalRate;

        const volumeFactor = 1.0 - userVolume * 0.05;
        const gainNode = audioCtx.createGain();
        gainNode.gain.value = Math.min(Math.max(volumeFactor, 0.85), 1.0);

        const panner = new StereoPannerNode(audioCtx, {
          pan: (Math.random() - 0.5) * 2
        });

        const filter = audioCtx.createBiquadFilter();
        filter.type = "bandpass";
        filter.frequency.value = 600 + (Math.random() * 800);
        filter.Q.value = 5;

        source.connect(filter).connect(panner).connect(gainNode).connect(audioCtx.destination);

        source.onended = () => {
          updateStatus("üîÑ Lecture termin√©e, red√©marrage...");
          setTimeout(startProcess, 500);
        };

        source.start();
        updateStatus(`‚ñ∂Ô∏è Lecture opposition ‚Äî rate: ${finalRate.toFixed(2)}, gain: ${gainNode.gain.value.toFixed(2)}`);
      })
      .catch(err => {
        console.error("Erreur lecture mp3:", err);
        updateStatus("‚ö†Ô∏è Erreur lecture MP3");
        setTimeout(startProcess, 1000);
      });
  }

  function randomFromArray(arr) {
    return arr[Math.floor(Math.random() * arr.length)];
  }

  function logTranscript(transcript, mp3) {
    const logBox = document.getElementById("log");
    const line = document.createElement("div");
    line.textContent = `üó£Ô∏è "${transcript}" ‚û°Ô∏è üéµ ${mp3}`;
    logBox.appendChild(line);
    logBox.scrollTop = logBox.scrollHeight;
  }
</script>

</body>
</html>

