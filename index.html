<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Mic Keyword Response</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      margin: 0;
      padding: 20px;
    }
    button {
      font-size: 18px;
      margin: 10px;
      padding: 10px 20px;
      cursor: pointer;
    }
  </style>
</head>
<body>

<h1>ðŸŽ¤ Mic Keyword Response</h1>
<button onclick="startProcess()">ðŸŽ§ DÃ©marrer</button>
<div id="status">PrÃªt.</div>

<script>
  const keywordMap = {
    "ok": "a5.mp3",
    "oui": "a4.mp3"
  };

  const fallbackClip = "fallback.mp3"; // Clip Ã  jouer si aucun mot-clÃ© n'est dÃ©tectÃ©
  const youSaidClip = "a5.mp3"; // Clip fixe avant la relecture de la voix

  let mediaRecorder;
  let recordedChunks = [];
  let recognition;
  let recordedBlob;

  function startProcess() {
    recordedChunks = [];
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
        playAudioSequence();
      };
      mediaRecorder.start();
      document.getElementById("status").textContent = "ðŸŽ™ï¸ Enregistrement 3s...";
      setTimeout(() => mediaRecorder.stop(), 3000);
    });
  }

  function playAudioSequence() {
    document.getElementById("status").textContent = "â–¶ï¸ Lecture : you said this.mp3";
    const youSaid = new Audio(youSaidClip);
    youSaid.onended = () => playUserRecording();
    youSaid.play();
  }

  function playUserRecording() {
    document.getElementById("status").textContent = "â–¶ï¸ Lecture de votre voix...";
    const playback = new Audio(URL.createObjectURL(recordedBlob));
    playback.onended = () => transcribeRecording();
    playback.play();
  }

  function transcribeRecording() {
    document.getElementById("status").textContent = "ðŸ§  Reconnaissance vocale...";
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      document.getElementById("status").textContent = "âŒ Reconnaissance non supportÃ©e.";
      return;
    }

    recognition = new SpeechRecognition();
    recognition.lang = "fr-FR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onresult = e => {
      const txt = e.results[0][0].transcript.toLowerCase();
      document.getElementById("status").textContent = `âœ… Vous avez dit : "${txt}"`;
      let matched = false;
      for (const key in keywordMap) {
        if (txt.includes(key)) {
          matched = true;
          playKeywordAudio(keywordMap[key]);
          return;
        }
      }
      if (!matched) {
        document.getElementById("status").textContent += " (aucun mot-clÃ© dÃ©tectÃ©)";
        playKeywordAudio(fallbackClip);
      }
    };

    recognition.onerror = e => {
      document.getElementById("status").textContent = "âŒ Erreur : " + e.error;
      playKeywordAudio(fallbackClip);
    };

    recognition.onend = () => {
      // If nothing was said, fallback will already play
    };

    recognition.start();
  }

  function playKeywordAudio(path) {
    document.getElementById("status").textContent = "â–¶ï¸ RÃ©ponse : " + path;
    const audio = new Audio(path);
    audio.onended = () => startProcess(); // boucle automatique
    audio.play();
  }
</script>

</body>
</html>

