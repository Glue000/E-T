<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Soft Opposition Voice Reaction</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
    button {
      font-size: 18px;
      margin: 10px;
      padding: 10px 20px;
      cursor: pointer;
    }
  </style>
</head>
<body>

<h1>üé§ Soft Opposition Voice Reaction</h1>
<button id="startBtn">üéß D√©marrer</button>
<div id="status">Pr√™t.</div>

<script>
  const keywordMap = {
    "ok": ["M/a2.mp3"],
    "oui": ["M/a3.mp3"]
  };
  const fallbackClips = ["M/merci1.mp3", "M/merci2.mp3", "M/merci3.mp3"];
  const recordStartSound = "click.mp3"; // replace with your start sound path
  const RECORD_DURATION = 3000; // milliseconds

  let audioCtx = null;
  let mediaRecorder = null;
  let recordedChunks = [];

  // Pitch, volume, speed global for playback adjustments
  let userPitch = 200, userVolume = 0.1, userSpeed = 0.05;

  // Start button event
  document.getElementById("startBtn").onclick = () => {
    startProcess();
  };

  async function startProcess() {
    try {
      if (!audioCtx) {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      }
      if (audioCtx.state === 'suspended') {
        await audioCtx.resume();
      }

      recordedChunks = [];
      updateStatus("üîä Jouer son de d√©marrage...");
      await playStartSound();

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // Start speech recognition at the same time as recording
      startRecognition();

      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
        analyzeAndPlay(recordedBlob);
      };

      mediaRecorder.start();
      updateStatus("üéôÔ∏è Enregistrement...");
      setTimeout(() => {
        mediaRecorder.stop();
      }, RECORD_DURATION);

    } catch (err) {
      console.error(err);
      updateStatus("‚ùå Erreur : " + err.message);
    }
  }

  function updateStatus(text) {
    document.getElementById("status").textContent = text;
  }

  function playStartSound() {
    return new Promise((resolve) => {
      const sound = new Audio(recordStartSound);
      sound.volume = 0.5;
      sound.onended = resolve;
      sound.onerror = () => resolve(); // ignore errors, resolve anyway
      sound.play().catch(() => resolve());
    });
  }

  function analyzeAndPlay(blob) {
    const reader = new FileReader();
    reader.onload = e => {
      audioCtx.decodeAudioData(e.target.result).then(buffer => {
        analyzeRecordedAudio(buffer);
        // Play the inverted mp3 based on last recognized keyword or fallback
        chooseAndPlayMP3();
      }).catch(err => {
        console.error("Audio decode error:", err);
        updateStatus("‚ö†Ô∏è Erreur d√©codage audio");
        restartProcessWithDelay();
      });
    };
    reader.readAsArrayBuffer(blob);
  }

  // Analyze PCM data for pitch, volume, speed
  function analyzeRecordedAudio(buffer) {
    const rawData = buffer.getChannelData(0);
    const sampleRate = buffer.sampleRate;

    // Pitch (autocorrelation)
    let maxCorr = 0, bestLag = 0;
    for (let lag = 16; lag < 1000; lag++) {
      let corr = 0;
      for (let i = 0; i < rawData.length - lag; i++) {
        corr += rawData[i] * rawData[i + lag];
      }
      if (corr > maxCorr) {
        maxCorr = corr;
        bestLag = lag;
      }
    }
    userPitch = bestLag > 0 ? (sampleRate / bestLag) : 200;

    // Volume RMS
    let sumSquares = 0;
    for (let i = 0; i < rawData.length; i++) {
      sumSquares += rawData[i] * rawData[i];
    }
    userVolume = Math.min(Math.sqrt(sumSquares / rawData.length), 1);

    // Speed (zero crossings)
    let crossings = 0;
    for (let i = 1; i < rawData.length; i++) {
      if ((rawData[i - 1] < 0 && rawData[i] >= 0) || (rawData[i - 1] > 0 && rawData[i] <= 0)) {
        crossings++;
      }
    }
    userSpeed = crossings / rawData.length;

    console.log(`Analyse: pitch=${userPitch.toFixed(1)}, volume=${userVolume.toFixed(2)}, speed=${userSpeed.toFixed(3)}`);
  }

  // Store recognized text globally for use in choosing mp3
  let lastRecognizedText = "";

  // Speech recognition function
  function startRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.warn("SpeechRecognition API non support√©");
      lastRecognizedText = "";
      return;
    }
    const recognition = new SpeechRecognition();
    recognition.lang = "fr-FR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onresult = e => {
      lastRecognizedText = e.results[0][0].transcript.toLowerCase();
      updateStatus(`‚úÖ Vous avez dit : "${lastRecognizedText}"`);
      console.log("Reconnu:", lastRecognizedText);
    };

    recognition.onerror = e => {
      console.warn("Erreur reconnaissance:", e.error);
      lastRecognizedText = "";
    };

    recognition.start();
    // Safety stop after record duration
    setTimeout(() => {
      try { recognition.stop(); } catch {}
    }, RECORD_DURATION);
  }

  // Pick mp3 to play based on keyword or fallback
  function chooseAndPlayMP3() {
    let foundKey = null;
    for (const key in keywordMap) {
      if (lastRecognizedText.includes(key)) {
        foundKey = key;
        break;
      }
    }
    let clipList = foundKey ? keywordMap[foundKey] : fallbackClips;
    const chosenPath = randomFromArray(clipList);
    playSoftOppositionMP3(chosenPath);
  }

  // Play mp3 with gentle opposite pitch, speed, volume
  function playSoftOppositionMP3(path) {
    fetch(path)
      .then(res => {
        if (!res.ok) throw new Error(`HTTP error! status: ${res.status}`);
        return res.arrayBuffer();
      })
      .then(data => audioCtx.decodeAudioData(data))
      .then(buffer => {
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;

        // Soft opposite factors (values close to 1)
        const pitchFactor = 1.1 - (userPitch / 800); // gentle inverse pitch
        const speedFactor = 1.05 - userSpeed * 0.5; // gentle inverse speed
        const volumeFactor = 1.0 - userVolume * 0.3; // softer volume when user loud

        // Clamp final playback rate and gain
        const finalRate = Math.min(Math.max(speedFactor * pitchFactor, 0.85), 1.15);
        source.playbackRate.value = finalRate;

        const gainNode = audioCtx.createGain();
        gainNode.gain.value = Math.min(Math.max(volumeFactor, 0.4), 1.0);

        // Mild filter for tonal opposition
        const filter = audioCtx.createBiquadFilter();
        filter.type = "lowshelf";
        filter.frequency.value = 800;
        filter.gain.value = pitchFactor > 1 ? -3 : 3;

        source.connect(filter).connect(gainNode).connect(audioCtx.destination);

        source.onended = () => {
          updateStatus("üîÑ Lecture termin√©e, red√©marrage...");
          setTimeout(() => startProcess(), 500); // small delay before restart
        };

        source.start();
        updateStatus(`‚ñ∂Ô∏è Lecture mp3 invers√©e douce ‚Äî rate: ${finalRate.toFixed(2)}, gain: ${gainNode.gain.value.toFixed(2)}`);
      })
      .catch(err => {
        console.error("Erreur lecture mp3:", err);
        updateStatus("‚ö†Ô∏è Erreur lecture MP3 : " + err.message);
        setTimeout(() => startProcess(), 1000);
      });
  }

  function randomFromArray(arr) {
    return arr[Math.floor(Math.random() * arr.length)];
  }
</script>

</body>
</html>
