<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Inverse Voice Reaction with Keywords & Start Sound</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
    button {
      font-size: 18px;
      margin: 10px;
      padding: 10px 20px;
      cursor: pointer;
    }
  </style>
</head>
<body>

<h1>üé§ Inverse Voice Reaction + Keywords</h1>
<button onclick="startProcess()">üéß D√©marrer</button>
<div id="status">Pr√™t.</div>

<script>
  const keywordMap = {
    "ok": ["M/a2.mp3"],
    "oui": ["M/a3.mp3"]
  };
  const fallbackClips = ["M/merci1.mp3", "M/merci2.mp3", "M/merci3.mp3"];
  const recordStartSound = "click.mp3"; // your start sound mp3 here
  const RECORD_DURATION = 3000;

  let mediaRecorder, audioCtx, analyser;
  let recordedChunks = [];
  let userPitch = 200, userVolume = 0.1, userSpeed = 0.05;

  async function startProcess() {
    try {
      if (!audioCtx) {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      }
      if (audioCtx.state === 'suspended') {
        await audioCtx.resume();
        console.log("AudioContext resumed");
      }

      recordedChunks = [];

      await playStartSound();

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);

      const micSource = audioCtx.createMediaStreamSource(stream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      micSource.connect(analyser);

      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);

      mediaRecorder.onstop = () => {
        const recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
        analyzeMicInput();
        transcribeRecording();
      };

      mediaRecorder.start();
      document.getElementById("status").textContent = "üéôÔ∏è Enregistrement...";
      setTimeout(() => mediaRecorder.stop(), RECORD_DURATION);

    } catch (err) {
      console.error("Error in startProcess:", err);
      document.getElementById("status").textContent = "‚ùå Erreur : " + err.message;
    }
  }

  function playStartSound() {
    return new Promise((resolve, reject) => {
      const sound = new Audio(recordStartSound);
      sound.volume = 0.5;
      sound.onended = resolve;
      sound.onerror = e => {
        console.warn("Start sound error", e);
        resolve(); // resolve anyway to not block
      };
      sound.play().catch(e => {
        console.warn("Play start sound failed", e);
        resolve();
      });
    });
  }

  function analyzeMicInput() {
    const bufferLength = analyser.fftSize;
    const data = new Float32Array(bufferLength);
    analyser.getFloatTimeDomainData(data);

    // Pitch estimation via autocorrelation
    let maxCorr = 0, bestLag = 0;
    for (let lag = 16; lag < 1000; lag++) {
      let corr = 0;
      for (let i = 0; i < bufferLength - lag; i++) {
        corr += data[i] * data[i + lag];
      }
      if (corr > maxCorr) {
        maxCorr = corr;
        bestLag = lag;
      }
    }
    userPitch = bestLag > 0 ? (audioCtx.sampleRate / bestLag) : 200;

    // Volume estimation (RMS)
    let sumSquares = 0;
    for (let i = 0; i < bufferLength; i++) {
      sumSquares += data[i] * data[i];
    }
    userVolume = Math.min(Math.sqrt(sumSquares / bufferLength), 1);

    // Speed estimation (zero-crossings)
    let crossings = 0;
    for (let i = 1; i < bufferLength; i++) {
      if ((data[i - 1] < 0 && data[i] >= 0) || (data[i - 1] > 0 && data[i] <= 0)) {
        crossings++;
      }
    }
    userSpeed = crossings / bufferLength;

    console.log(`analyzeMicInput: pitch=${userPitch.toFixed(1)}, volume=${userVolume.toFixed(2)}, speed=${userSpeed.toFixed(3)}`);
  }

  function transcribeRecording() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.warn("SpeechRecognition API not supported");
      playRandomFallback();
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "fr-FR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onresult = e => {
      const txt = e.results[0][0].transcript.toLowerCase();
      document.getElementById("status").textContent = `‚úÖ Vous avez dit : "${txt}"`;
      console.log("Recognized text:", txt);
      for (const key in keywordMap) {
        if (txt.includes(key)) {
          const responsePath = randomFromArray(keywordMap[key]);
          playInvertedMP3(responsePath);
          return;
        }
      }
      playRandomFallback();
    };

    recognition.onerror = e => {
      console.error("Speech recognition error:", e.error);
      document.getElementById("status").textContent = "‚ùå Erreur reconnaissance : " + e.error;
      playRandomFallback();
    };

    recognition.start();
    // Safety stop after 3 sec
    setTimeout(() => {
      try {
        recognition.stop();
      } catch {}
    }, 3000);
  }

  function playRandomFallback() {
    const responsePath = randomFromArray(fallbackClips);
    playInvertedMP3(responsePath);
  }

  function playInvertedMP3(path) {
    fetch(path)
      .then(res => {
        if (!res.ok) throw new Error(`HTTP error! status: ${res.status}`);
        return res.arrayBuffer();
      })
      .then(data => audioCtx.decodeAudioData(data))
      .then(buffer => {
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;

        const pitchFactor = 1.3 - (userPitch / 400);
        const speedFactor = 1.1 - userSpeed;
        const volumeFactor = 1.4 - userVolume * 1.2;

        const finalRate = Math.min(Math.max(speedFactor * pitchFactor, 0.75), 1.3);
        source.playbackRate.value = finalRate;

        const gainNode = audioCtx.createGain();
        gainNode.gain.value = Math.min(Math.max(volumeFactor, 0.5), 1.5);

        const filter = audioCtx.createBiquadFilter();
        filter.type = "lowshelf";
        filter.frequency.value = 1000;
        filter.gain.value = pitchFactor > 1 ? -5 : 5;

        source.connect(filter).connect(gainNode).connect(audioCtx.destination);

        source.onended = () => {
          console.log("Playback ended, restarting process");
          startProcess();
        };

        source.start();
        document.getElementById("status").textContent =
          `üîÑ R√©action invers√©e ‚Äî rate: ${finalRate.toFixed(2)}, gain: ${gainNode.gain.value.toFixed(2)}`;
      })
      .catch(err => {
        console.error("Error playing mp3:", err);
        document.getElementById("status").textContent = "‚ö†Ô∏è Erreur lecture MP3 : " + err.message;
        startProcess();
      });
  }

  function randomFromArray(arr) {
    return arr[Math.floor(Math.random() * arr.length)];
  }
</script>

</body>
</html>
