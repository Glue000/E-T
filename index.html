<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Mic Keyword Response</title>
  <style>
    body {
      background: black;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
    button {
      font-size: 18px;
      margin: 10px;
      padding: 10px 20px;
      cursor: pointer;
    }
  </style>
</head>
<body>

<h1>🎤 Mic Keyword Response 0.5</h1>
<button onclick="startProcess()">🎧 Démarrer</button>
<div id="status">Prêt.</div>

<script>
  const keywordMap = {
    "ok": ["M/a2.mp3"],
    "oui": ["M/a3.mp3"]
  };
  const fallbackClips = ["M/merci1.mp3"];
  const youSaidClip = "positifR1.mp3";
  const RECORD_DURATION = 3000; // <-- change this to adjust recording time

  let mediaRecorder;
  let recordedChunks = [];
  let recordedBlob;

  function startProcess() {
    recordedChunks = [];
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
        playYouSaidSequence();
      };
      mediaRecorder.start();
      document.getElementById("status").textContent = "🎙️ Enregistrement...";
      setTimeout(() => mediaRecorder.stop(), RECORD_DURATION);
    });
  }

  function playYouSaidSequence() {
    document.getElementById("status").textContent = "▶️ Lecture : 'Tu as dit...'";
    const youSaid = new Audio(youSaidClip);
    youSaid.onended = () => playUserRecording();
    youSaid.play();
  }

  function playUserRecording() {
    document.getElementById("status").textContent = "▶️ Lecture de votre voix...";
    const playback = new Audio(URL.createObjectURL(recordedBlob));
    playback.onended = () => transcribeRecording();
    playback.play();
  }

  function transcribeRecording() {
    document.getElementById("status").textContent = "🧠 Reconnaissance vocale...";

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      document.getElementById("status").textContent = "❌ Reconnaissance non supportée.";
      playResponse(fallbackClips);
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "fr-FR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onresult = e => {
      const txt = e.results[0][0].transcript.toLowerCase();
      document.getElementById("status").textContent = `✅ Vous avez dit : "${txt}"`;
      for (const key in keywordMap) {
        if (txt.includes(key)) {
          playResponse(keywordMap[key]);
          return;
        }
      }
      playResponse(fallbackClips);
    };

    recognition.onerror = e => {
      document.getElementById("status").textContent = "❌ Erreur : " + e.error;
      playResponse(fallbackClips);
    };

    recognition.start();
    setTimeout(() => recognition.stop(), 3000);
  }

  function playResponse(list) {
    const path = list[Math.floor(Math.random() * list.length)];
    document.getElementById("status").textContent = "▶️ Réponse : " + path;
    const response = new Audio(path);
    response.onended = () => startProcess(); // restart after response
    response.play();
  }
</script>

</body>
</html>

